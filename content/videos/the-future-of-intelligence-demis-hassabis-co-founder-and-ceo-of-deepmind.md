---
share: true
aliases:
  - ğŸ¤–ğŸ§ ğŸ“ˆ The future of intelligence | Demis Hassabis (Co-founder and CEO of DeepMind)
title: ğŸ¤–ğŸ§ ğŸ“ˆ The future of intelligence | Demis Hassabis (Co-founder and CEO of DeepMind)
URL: https://bagrounds.org/videos/the-future-of-intelligence-demis-hassabis-co-founder-and-ceo-of-deepmind
Author:
Platform:
Channel: Google DeepMind
tags:
youtube: https://youtu.be/PqVbypvxDto
---
[Home](../index.md) > [Videos](./index.md)  
# ğŸ¤–ğŸ§ ğŸ“ˆ The future of intelligence | Demis Hassabis (Co-founder and CEO of DeepMind)  
![The future of intelligence | Demis Hassabis (Co-founder and CEO of DeepMind)](https://youtu.be/PqVbypvxDto)  
  
## ğŸ¤– AI Summary  
  
* ğŸ§  Effort is split equally between scaling existing models and inventing new architectures to reach general intelligence.  
* âš›ï¸ Partnerships like the one with Commonwealth Fusion aim to solve root node problems like clean energy and material science.  
* ğŸ§© Current models exhibit jagged intelligence where they master PhD level math but fail at basic high school logic.  
* ğŸ”„ Continuous online learning is a critical missing piece for systems to improve through interaction after training.  
* âš–ï¸ The commercial race for chatbots accelerated progress and public access but complicated the path of rigorous lab science.  
* ğŸ“ˆ Scaling laws have not hit a wall, though gains are moving from exponential leaps to significant steady improvements.  
* â˜ï¸ Synthetic data and self-generation methods are overcoming potential limits on available human training data.  
* ğŸŒ World models and simulations enable agents to learn intuitive physics and spatial awareness beyond what text provides.  
* ğŸ® Gaming environments serve as sandboxes for agents to develop curiosity-driven exploration and solve complex tasks.  
* ğŸ›ï¸ Society requires new economic models and institutions to manage a transition ten times faster than the Industrial Revolution.  
* ğŸ›¡ï¸ Agentic AI increases autonomy risks, requiring proactive development of cyber defenses and international safety standards.  
* ğŸ§¬ Biology is fundamentally an information processing system that computable models will eventually use to cure all diseases.  
  
## ğŸ¤” Evaluation  
  
* âš–ï¸ Hassabis frames AI as a tool for scientific abundance, while sources like The Coming Wave by Mustafa Suleyman (Crown) emphasize the inherent danger of proliferation and the difficulty of containment.  
* ğŸ“‰ While Google highlights model strengths, reports from the AI Index by Stanford University (Stanford Institute for Human-Centered AI) point to the plateauing of performance on traditional benchmarks and the massive environmental costs of training.  
* ğŸ’¸ The optimistic view of post-scarcity contrasts with analysis in The Age of AI by Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher (Little, Brown and Company), which warns that AI may erode human reason and traditional geopolitical stability.  
* ğŸ”¬ Understanding the specific technical hurdles of AI safety requires exploring Formal Verification for Deep Learning as discussed in research from the Future of Humanity Institute (University of Oxford).  
  
## â“ Frequently Asked Questions (FAQ)  
  
### ğŸ•’ Q: What is the expected timeline for Artificial General Intelligence?  
  
ğŸ•’ A: Development is moving rapidly with significant milestones expected within five to ten years as models transition from passive assistants to autonomous agents.  
  
### ğŸ§ª Q: How does AlphaFold contribute to modern medical science?  
  
ğŸ§ª A: It acts as a proof of concept for solving root node problems by predicting protein structures, which accelerates drug discovery and the understanding of biological systems.  
  
### ğŸ’° Q: Is the current investment in AI a market bubble?  
  
ğŸ’° A: While some startup valuations may be unsustainable, the underlying business value is supported by real products like search, workspace tools, and revolutionary scientific advancements.  
  
### ğŸ›‘ Q: How can hallucinations in AI models be stopped?  
  
ğŸ›‘ Q: Solutions include developing internal confidence scores, implementing thinking steps for self-correction, and grounding models in simulated physical environments with ground truth data.  
  
## ğŸ“š Book Recommendations  
  
### â†”ï¸ Similar  
  
* [ğŸ§¬ğŸ‘¥ğŸ’¾ Life 3.0: Being Human in the Age of Artificial Intelligence](../books/life-3-0.md) by Max Tegmark (Knopf) examines the future of intelligence and the potential paths toward AGI.  
* [ğŸ¤–âš ï¸ğŸ“ˆ Superintelligence: Paths, Dangers, Strategies](../books/superintelligence-paths-dangers-strategies.md) by Nick Bostrom (Oxford University Press) provides a deep dive into the risks and strategic challenges of superintelligent systems.  
  
### ğŸ†š Contrasting  
  
* ğŸ“™ The Myth of Artificial Intelligence by Erik J. Larson (Belknap Press) argues that current computational methods are fundamentally incapable of achieving true human-like intuition.  
* [ğŸ“ŠğŸ“‰ğŸ›ï¸ Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](../books/weapons-of-math-destruction-how-big-data-increases-inequality-and-threatens-democracy.md) by Cathy O'Neil (Crown) highlights the societal harms and biases already present in algorithmic decision-making.  
  
### ğŸ¨ Creatively Related  
  
* ğŸ“— The Glass Bead Game by Hermann Hesse (Suhrkamp) explores a future where all knowledge is synthesized into a complex, meditative system.  
* ğŸ“— Permutation City by Greg Egan (Millennium) is a science fiction novel that investigates the philosophical implications of consciousness in simulated environments.