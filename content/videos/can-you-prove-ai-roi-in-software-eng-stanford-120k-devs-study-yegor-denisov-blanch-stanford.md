---
share: true
aliases:
  - ğŸ¤–ğŸ“ˆ ğŸ’¯ğŸ“Š ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’» Can you prove AI ROI in Software Eng? (Stanford 120k Devs Study) â€“ Yegor Denisov-Blanch, Stanford
title: ğŸ¤–ğŸ“ˆ ğŸ’¯ğŸ“Š ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’» Can you prove AI ROI in Software Eng? (Stanford 120k Devs Study) â€“ Yegor Denisov-Blanch, Stanford
URL: https://bagrounds.org/videos/can-you-prove-ai-roi-in-software-eng-stanford-120k-devs-study-yegor-denisov-blanch-stanford
Author:
Platform:
Channel: AI Engineer
tags:
youtube: https://youtu.be/JvosMkuNxF8
---
[Home](../index.md) > [Videos](./index.md)  
# ğŸ¤–ğŸ“ˆ ğŸ’¯ğŸ“Š ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’» Can you prove AI ROI in Software Eng? (Stanford 120k Devs Study) â€“ Yegor Denisov-Blanch, Stanford  
![Can you prove AI ROI in Software Eng? (Stanford 120k Devs Study) â€“ Yegor Denisov-Blanch, Stanford](https://youtu.be/JvosMkuNxF8)  
  
## ğŸ¤– AI Summary  
* ğŸ”¬ Research measures AI impact on software engineering productivity using a machine learning model that replicates a 10-15 expert panel evaluation across implementation time, maintainability, and complexity \[[00:50](http://www.youtube.com/watch?v=JvosMkuNxF8&t=50)].  
* ğŸ“ˆ Median net productivity gain from AI adoption stands at about 10% for the measured team cohort \[[02:24](http://www.youtube.com/watch?v=JvosMkuNxF8&t=144)].  
* âš ï¸ The gap between top-performing and bottom-performing AI teams is widening, suggesting a rich gets richer effect for successful early adopters \[[02:32](http://www.youtube.com/watch?v=JvosMkuNxF8&t=152)].  
* âš™ï¸ AI usage quantity (token spent) loosely correlates (0.20 R-squared) with productivity gains; usage quality matters more than volume \[[03:30](http://www.youtube.com/watch?v=JvosMkuNxF8&t=210)].  
* ğŸ§¼ Codebase hygiene is key: a decent correlation (0.40 R-squared) exists between environment cleanliness (tests, documentation) and AI productivity gains \[[04:29](http://www.youtube.com/watch?v=JvosMkuNxF8&t=269)].  
* ğŸ“‰ Unchecked AI use accelerates codebase technical debt; human effort maintains cleanliness and sustains AI benefits \[[05:23](http://www.youtube.com/watch?v=JvosMkuNxF8&t=323)].  
* ğŸ›¡ï¸ Engineers must know when to use AI; rejected or rewritten AI outputs erode trust, collapsing AI gains \[[05:51](http://www.youtube.com/watch?v=JvosMkuNxF8&t=351)].  
* ğŸ¯ Measuring AI Return on Investment (ROI) must focus on engineering outcomes, not noisy business outcomes \[[09:15](http://www.youtube.com/watch?v=JvosMkuNxF8&t=555)].  
* ğŸ“Š The framework uses Engineering Output, based on the expert-replicating ML model, as the primary metric, not just Lines of Code or Pull Request (PR) counts \[[12:00](http://www.youtube.com/watch?v=JvosMkuNxF8&t=720)].  
* ğŸš¨ Case study: one team saw PRs increase by 14% but code quality decreased by 9%, effective output did not increase, and rework increased by 2.5 times \[[14:50](http://www.youtube.com/watch?v=JvosMkuNxF8&t=890)].  
* ğŸ’¡ Measuring only PR count is misleading and can hide negative ROI; thorough measurement is necessary to course correct AI adoption \[[15:11](http://www.youtube.com/watch?v=JvosMkuNxF8&t=911)].  
  
## ğŸ¤” Evaluation  
* âœ… **Video Claim Supported (10% median gain)**: The 10% median productivity gain aligns with some studies showing positive effects, like a McKinsey report finding developers can complete tasks up to twice as fast (McKinsey) and MIT Sloan research averaging a 26% increase in completed weekly tasks (MIT Sloan).  
* âŒ **Video Claim Contrasted (Code Quality)**: The video's case study showing code quality decreasing by 9% \[[14:50](http://www.youtube.com/watch?v=JvosMkuNxF8&t=890)] is supported by the Faros AI report The AI Productivity Paradox Research Report, which found AI adoption is consistently associated with a 9% increase in bugs (Faros AI).  
* â†”ï¸ **Contrasting Productivity Gains**: The modest 10% median gain contrasts sharply with an RCT by Metr.org researchers, which found experienced open-source developers took **19% longer** to complete tasks with early-2025 AI tools, despite believing they sped up (Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity, Metr.org).  
* âš–ï¸ **Agreement on Measurement**: The video's move beyond simple metrics like PR counts \[[12:00](http://www.youtube.com/watch?v=JvosMkuNxF8&t=720)] is echoed by multiple sources. The AWS blog Measuring the Impact of AI Assistants on Software Development emphasizes measuring the entire delivery system, not just individual coding speed (AWS).  
  
## ğŸ” **Topics for Better Understanding**  
* ğŸ¤” **The Rich Get Richer Effect**: Explore training and governance strategies that successfully bridge the widening productivity gap between high and low-performing AI teams.  
* ğŸ› ï¸ **Operationalizing Cleanliness**: Investigate concrete, measurable engineering practices and tooling investments that maximize the environment cleanliness index to unlock AI gains in various technology stacks.  
* ğŸ¤ **Shared Authorship and Trust**: Research the long-term impact on engineering culture and skill atrophy when developers increasingly edit/review AI-generated code, especially concerning the shared sense of authorship and trust \[[05:51](http://www.youtube.com/watch?v=JvosMkuNxF8&t=351)].  
  
## â“ Frequently Asked Questions (FAQ)  
### ğŸ“ˆ Q: What is the proven Return on Investment (ROI) for AI in software engineering?  
âœ… A: While individual developer throughput may increase, the median net productivity gain from AI tools in enterprise software engineering is around **10%** based on a Stanford study tracking 46 matched teams (Can you prove AI ROI in Software Eng? Stanford 120k Devs Study). The true gain is highly variable and depends on codebase quality.  
  
### ğŸ“ Q: Why are traditional metrics like Pull Request count or Lines of Code misleading for measuring AI impact?  
ğŸ“‰ A: Traditional metrics like Pull Requests (PRs) reflect **volume**, not value. A team in the study saw a 14% PR increase but their **code quality dropped by 9%** and **rework increased by 2.5 times** \[[14:50](http://www.youtube.com/watch?v=JvosMkuNxF8&t=890)], masking a potential negative ROI. Quality-focused metrics, like **Engineering Output** based on expert evaluation, are necessary to capture the true effect \[[12:00](http://www.youtube.com/watch?v=JvosMkuNxF8&t=720)].  
  
### ğŸ”‘ Q: What is the most important factor for successfully leveraging AI tools in a codebase?  
ğŸ§¼ A: The most critical factor is **codebase hygiene** or environment cleanliness. Research found a decent correlation (0.40 R-squared) between a cleanliness index (tests, documentation, modularity) and AI productivity gains \[[04:29](http://www.youtube.com/watch?v=JvosMkuNxF8&t=269)]. Teams must **invest in a clean codebase** and guard against AI accelerating technical debt.  
  
## ğŸ“š Book Recommendations  
### â†”ï¸ Similar  
* [ğŸï¸ğŸ’¾ Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations](../books/accelerate.md) by Nicole Forsgren, Jez Humble, and Gene Kim. This book establishes the DORA metrics and emphasizes that deployment frequency and stability are the best predictors of organizational performance.  
* [ğŸ§‘â€ğŸ¤â€ğŸ§‘âš™ï¸â¡ï¸ Team Topologies: Organizing Business and Technology Teams for Fast Flow](../books/team-topologies-organizing-business-and-technology-teams-for-fast-flow.md) by Matthew Skelton and Manuel Pais. It discusses organizing teams for rapid, sustainable flow of software delivery, relating to managing bottlenecks in the engineering system.  
* ğŸ¤– The AI-Powered Company: How to Use Artificial Intelligence to Attract and Retain Customers by Dave Blakely and Mark Johnson. This book provides a business-centric view on how companies should structure themselves and their processes to adopt AI effectively.  
  
### ğŸ†š Contrasting  
* [ğŸ¦„ğŸ‘¤ğŸ—“ï¸ The Mythical Man-Month: Essays on Software Engineering](../books/the-mythical-man-month.md) by Frederick Brooks Jr. This classic book emphasizes the inherent complexity of software projects and the challenges of scaling in a pre-AI world.  
* [ğŸ¤¿ğŸ’¼ Deep Work: Rules for Focused Success in a Distracted World](../books/deep-work.md) by Cal Newport. This book contrasts with the high-velocity, multi-stream environment AI creates, arguing for the value of long periods of focused concentration on cognitively demanding tasks.  
* [âœ…ğŸ’» Code Complete](../books/code-complete.md): A Practical Handbook of Software Construction by Steve McConnell. This reference provides detailed instruction on software construction practices, offering a baseline of best practices against which to contrast the risks of AI-driven quality degradation.  
  
### ğŸ¨ Creatively Related  
- [ğŸ¤–ğŸ—ï¸ AI Engineering: Building Applications with Foundation Models](../books/ai-engineering-building-applications-with-foundation-models.md)  
* [ğŸ¤”ğŸ‡ğŸ¢ Thinking, Fast and Slow](../books/thinking-fast-and-slow.md) by Daniel Kahneman. This book describes System 1 (fast, intuitive) and System 2 (slow, deliberate) thinking, creatively relating to how AI provides a powerful System 1 aid, but human System 2 review is essential for quality.  
* [ğŸ”¬ğŸ”„ The Structure of Scientific Revolutions](../books/the-structure-of-scientific-revolutions.md) by Thomas S. Kuhn. This book explores how fields undergo paradigm shifts, tangentially relating to the disruption AI brings and the need for new measurement frameworks.  
* [ğŸ“ğŸŒŒ How to Measure Anything: Finding the Value of Intangibles in Business](../books/how-to-measure-anything.md) by Douglas W. Hubbard. This is highly relevant as it focuses on the logic and methods for quantifying seemingly intangible concepts, similar to the video's attempt to measure Engineering Output.