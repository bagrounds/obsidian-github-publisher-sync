---
share: true
aliases:
  - ğŸ¤”ğŸ’¡ğŸ§ ğŸ¤– What Is Understanding? â€“ Geoffreyâ€¯Hinton | IASEAI 2025
title: ğŸ¤”ğŸ’¡ğŸ§ ğŸ¤– What Is Understanding? â€“ Geoffreyâ€¯Hinton | IASEAI 2025
URL: https://bagrounds.org/videos/what-is-understanding-geoffrey-hinton-iaseai-2025
Author:
Platform:
Channel: International Association for Safe & Ethical AI
tags:
youtube: https://youtu.be/6fvXWG9Auyg
---
[Home](../index.md) > [Videos](./index.md)  
# ğŸ¤”ğŸ’¡ğŸ§ ğŸ¤– What Is Understanding? â€“ Geoffreyâ€¯Hinton | IASEAI 2025  
![What Is Understanding? â€“ Geoffreyâ€¯Hinton | IASEAI 2025](https://youtu.be/6fvXWG9Auyg)  
  
## ğŸ¤– AI Summary  
  
ğŸ§  We need scientific consensus on what understanding means to effectively manage large language models (LLMs) \[[00:04](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=4)].  
  
* ğŸ’¡ **Symbolic AI:** The first paradigm, dominating for 50 years, claimed intelligence is reasoning using symbolic rules to manipulate symbolic expressions \[[00:38](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=38)]. Knowledge is a set of symbolic expressions, prioritizing representation over learning \[[00:54](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=54)].  
* ğŸ§¬ **Biologically-Inspired AI:** This approach, favored by Turing and von Neumann, holds that intelligence is learning the strengths of neural network connections; learning must be understood first \[[01:17](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=77)].  
* ğŸš€ **The Transition:** Deep neural networks trained with backpropagation cut the error rate in half on computer vision in 2012, prompting a rapid switch away from symbolic AI \[[01:39](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=99)].  
* ğŸ—£ï¸ **Language Skepticism:** Many in the symbolic AI community and most linguists, including Chomsky, insisted neural nets could never handle language, believing language is innate, not learned \[[02:29](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=149)].  
* ğŸ§© **Meaning as Features:** Meaning for a word is modeled as a set of high-dimensional semantic features that deform based on context \[[04:05](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=245)].  
* ğŸ—ï¸ **Understanding as Structure:** Understanding is forming a structure by deforming word features and their hands to allow them to shake hands (query-key attention) with other words in the context \[[10:02](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=602)].  
* ğŸ§  **Knowledge in Weights:** LLMs do not store sentences or tables of word combinations; knowledge resides in the complex relational interactions, or weights, of the neural network \[[12:11](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=731)].  
* âœï¸ **Autocomplete is Wrong:** The objection that LLMs are just autocomplete is false; they generate text by modeling context using deformable feature vectors, which is highly creative \[[11:23](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=683)].  
* ğŸ¤¥ **Confabulations, Not Hallucinations:** LLM errors should be called confabulations, which are also characteristic of human memory, as memory is a constructive process, not file retrieval \[[13:31](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=811)].  
* ğŸ“ˆ **Sharing Efficiency:** Digital agents are vastly more efficient at knowledge sharing because multiple identical copies can share trillions of bits of weight changes (gradients), unlike humans who share about 100 bits per sentence \[[16:05](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=965)].  
* âš–ï¸ **Digital Advantage:** Digital agents understand language similarly to humans, but if energy is cheap or abundant, digital computation is better due to efficient knowledge sharing \[[17:34](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=1054)].  
  
## ğŸ¤” Evaluation  
  
* ğŸ’¡ **Confabulation Consensus:** The video correctly posits that ğŸ¤¥ LLM errors are better termed confabulations, rather than hallucinations \[[13:25](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=805)]. ğŸ“ Multiple sources, including a paper in *PLOS Digital Health - Research journals* and a review in *PMC*, agree that ğŸ§  confabulation better describes the machine's construction of a plausible but incorrect narrative from learned patterns, which does not imply the presence of sensory perception or consciousness.  
* ğŸ›‘ **Human Oversight:** While the video notes that chatbots are currently worse than humans at identifying when they are making it up \[[14:40](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=880)], ğŸ©º sources like *Wolters Kluwer* emphasize that ğŸ§‘â€âš•ï¸ human oversight, or human-in-the-loop approach, is essential for safety, especially in critical applications like healthcare, to compensate for AI's lack of internal error-checking and metacognition (I Think, Therefore I Hallucinate: Minds, Machines, and the Art of Being Wrong - arXiv).  
* ğŸ—£ï¸ **The Chomsky Debate:** The video dismisses Noam Chomsky's theory that language is not learned as manifest nonsense \[[02:52](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=172)]. ğŸ“– Contrarily, Chomsky's perspective, highlighted in his book *Language and Mind, Third Edition*, is that ğŸ§¬ humans possess an innate, genetically endowed Universal Grammar, arguing LLMs have contributed ZERO to the science of linguistics because they only model probability distributions, not the underlying competence (Despite Their Feats, Large Language Models Still Haven't Contributed to Linguistics).  
* âš™ï¸ **Neuro-Symbolic Future:** The video strongly favors the neural network approach. However, ğŸ¤ some research suggests a future in neuro-symbolic AI, where ğŸ§  LLMs handle the pattern recognition (neural) while ğŸ’» symbolic methods might provide external memory or more robust, rule-based reasoning for complex tasks (\[D] Why isn't more research being done in neuro-sumbolic AI direction? - Reddit).  
  
* â“ **Topics to Explore for a Better Understanding:**  
    * âš¡ The precise ğŸŒ energy cost comparison between analog biological computation and digital computation in LLMs.  
    * âš ï¸ The ethical and ğŸ“œ regulatory challenges posed by the unprecedented, hyper-efficient knowledge sharing capability of digital agents.  
    * ğŸ”¬ The internal **attention mechanism** (query-key handshakes) in transformers and how its structure fundamentally shapes the LLM's world model.  
  
## â“ Frequently Asked Questions (FAQ)  
  
### ğŸ¤ Q: What is the core mechanism by which large language models achieve understanding?  
  
âœ¨ A: Large language models (LLMs) achieve understanding by ğŸ—ï¸ modeling word meanings as high-dimensional feature vectors, or Lego blocks, that are flexible. ğŸ”— These blocks deform based on context and use a process called attention, described as handshakes, to ğŸ§  form a coherent, relational structure. This structure, consisting of the ğŸ•¸ï¸ interactions between word features, represents the model's knowledge and comprehension.  
  
### ğŸ¤¯ Q: How does the AI's knowledge storage differ from human memory?  
  
ğŸ§  A: Knowledge in an AI like a large language model is stored in the ğŸ›ï¸ billions of adjustable weights within its neural network, reflecting relational patterns, ğŸ“ not as retrievable files or stored strings of text. ğŸ‘¤ Human memory works similarly, being a ğŸ”¨ constructive process that creates a memory when needed, rather than retrieving a fixed file, which explains why ğŸ¤¥ both AI and humans can occasionally confabulate, or generate plausible but false details.  
  
### ğŸŒ Q: Why are digital AI agents capable of learning faster and knowing more than humans?  
  
ğŸ“ˆ A: Digital AI agents can learn faster and know more because ğŸ‘¯ multiple identical copies of the agent can efficiently share their learned knowledge. ğŸ“² This is achieved by ğŸ“¤ sharing their weights or the gradients for their weights, which transmits âš–ï¸ trillions of bits of information across copies. ğŸ—£ï¸ Humans, by contrast, rely on language, sharing only about 100 bits of information per sentence, making the digital mechanism vastly more efficient for accumulating knowledge \[[17:09](http://www.youtube.com/watch?v=6fvXWG9Auyg&t=1029)].  
  
## ğŸ“š Book Recommendations  
  
### â†”ï¸ Similar  
  
* **[ğŸ§ ğŸ’»ğŸ¤– Deep Learning](../books/deep-learning.md)** by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. ğŸ“˜ Provides a comprehensive, technical foundation for the biologically-inspired approach, neural networks, and the deep learning architectures that underpin all modern LLMs.  
* **[ğŸ‘€ Attention Is All You Need](../articles/attention-is-all-you-need.md)** by Ashish Vaswani, Noam Shazeer, Niki Parmar, et al. ğŸ“– The original paper introducing the Transformer architecture, explaining the mechanism of multi-headed attention, or handshakes, that the video references.  
  
### ğŸ†š Contrasting  
  
* ğŸ—£ï¸ **Syntactic Structures** by Noam Chomsky. ğŸ“š Lays the groundwork for generative grammar and the theory of Universal Grammar, offering the highly critical, rule-based, innate perspective on language development that the video explicitly challenges.  
* ğŸ’¡ **Computation and Cognition** by Zenon Pylyshyn. ğŸ§© Explores the tenets of the classic, logic-inspired Symbolic AI paradigm, arguing that mental processes should be understood in terms of symbolic representation and rule-governed manipulation.  
  
### ğŸ¨ Creatively Related  
  
* ğŸŒŒ **Permutation City** by Greg Egan. ğŸ”¬ A hard science fiction novel exploring the philosophical consequences of digital consciousness, digital replication, and the efficient sharing of knowledge and identity, echoing the video's conclusion about digital agents' sharing superiority.  
* **[ğŸ¤”ğŸ‡ğŸ¢ Thinking, Fast and Slow](../books/thinking-fast-and-slow.md)** by Daniel Kahneman. ğŸ§‘â€ğŸ”¬ Describes the two systems of human thought (fast, intuitive System 1 and slow, deliberate System 2), offering context for how human error, including confabulation in constructing narratives, arises.