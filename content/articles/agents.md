---
share: true
aliases:
  - ğŸ•µï¸â€â™€ï¸ğŸ’¼ğŸ‘¥ Agents
title: ğŸ•µï¸â€â™€ï¸ğŸ’¼ğŸ‘¥ Agents
URL: https://bagrounds.org/articles/agents
Author: 
tags: 
---
[Home](../index.md) > [Articles](./index.md)  
# [ğŸ•µï¸â€â™€ï¸ğŸ’¼ğŸ‘¥ Agents](https://huyenchip.com//2025/01/07/agents.html)  
  
## ğŸ¤– AI Summary  
ğŸ¤– **Agents** are ğŸ¯ anything that can **perceive** its environment and **act** upon that environment.  
ğŸ§  **AI** is the **brain** that âš™ï¸ **processes** the task, ğŸ—ºï¸ **plans** a sequence of actions, and ğŸ•µï¸â€â™€ï¸ **determines** whether the task has been accomplished.  
ğŸ”‘ The ğŸ“ˆ **success** of an agent depends on the **tools** it has access to and the **strength** of its AI planner.  
  
### ğŸ› ï¸ Tools  
ğŸ”Œ **External tools** make an agent ğŸš€ vastly more capable, allowing it to both ğŸ‘ï¸ **perceive** the environment (read-only actions) and âœï¸ **act** upon it (write actions).  
ğŸ“š **Knowledge augmentation** tools ğŸ’¡ augment the agent's knowledge, such as ğŸ“„ text retrievers, ğŸ–¼ï¸ image retrievers, and ğŸ“Š SQL executors.  
ğŸŒ **Web Browse** is an umbrella term for tools that ğŸŒ access the internet, preventing models from becoming â³ stale and enabling access to ğŸ“° up-to-date information.  
ğŸ’ª **Capability extension** tools ğŸ“ˆ address inherent limitations of AI models, such as â• calculators for math, ğŸ§‘â€ğŸ’» code interpreters for execution, and ğŸ—£ï¸ translators for language.  
ğŸ¨ Tools can also turn ğŸ“ text-only or ğŸ–¼ï¸ image-only models into ğŸŒŸ **multimodal** models by leveraging other models (e.g., DALL-E for image generation).  
  
### ğŸ—ºï¸ Planning  
ğŸ§  **Foundation models** are used as **planners** to ğŸ’¡ process tasks, ğŸ“Š plan action sequences, and âœ… determine task completion.  
â“ An **open question** is how well foundation models can plan, with some researchers believing autoregressive LLMs ğŸš« cannot plan effectively.  
ğŸ” **Planning** is fundamentally a **search problem**, involving searching among different paths to a goal and predicting outcomes.  
ğŸ”™ While some argue autoregressive models cannot â†©ï¸ backtrack, they can ğŸ”„ revise paths or ğŸ”„ start over if a chosen path is not promising.  
ğŸš§ **Planning failures** can occur due to ğŸ˜µ hallucinated action sequences or incorrect parameters.  
ğŸ’¡ **Tips for better planning** include âœï¸ writing better system prompts, ğŸ“š giving better tool descriptions, â™»ï¸ refactoring complex functions, ğŸš€ using stronger models, and ğŸ§‘â€ğŸ« finetuning models for plan generation.  
ğŸ“ **Function calling** is the process of invoking tools, where tools are described by their execution entry point, parameters, and documentation.  
ğŸ“ **Planning granularity** refers to the level of detail in a plan; a detailed plan is harder to generate but easier to execute, while a higher-level plan is easier to generate but harder to execute.  
 hierarchical planning can circumvent this trade-off by generating high-level plans first, then more detailed plans for each sub-section.  
  
### ğŸš¨ Agent Failure Modes and Evaluation  
ğŸ“‰ **Compound mistakes** mean that overall accuracy decreases as the number of steps an agent performs increases.  
ğŸ’° **Higher stakes** tasks mean failures could have more severe consequences.  
â±ï¸ **Efficiency** concerns relate to agents consuming significant API credits or time for multi-step tasks.  
ğŸ§ When working with agents, it's advised to always ask the system to report what parameter values it uses for each function call and inspect these values for correctness.  
  
## ğŸ¤” Evaluation  
The article presents a clear and concise framework for understanding AI agents, focusing on their components, capabilities, and challenges. It effectively defines agents and elaborates on the critical roles of tools and planning. The comparison with Anthropic's blog post highlights conceptual alignment while emphasizing the unique focus on planning, tool selection, and failure modes in this article.  
  
To gain a better understanding, it would be beneficial to explore:  
* âš–ï¸ **Real-world case studies**: ğŸŒ Practical examples of successful and unsuccessful agent deployments across various industries could provide deeper insights into their practical implications and limitations.  
* ğŸ“Š **Quantitative evaluation metrics**: ğŸ“ While the article discusses failure modes, more specific quantitative metrics and benchmarks for evaluating agent performance beyond anecdotal evidence would be valuable.  
* ğŸ”¬ **Advancements in planning for LLMs**: ğŸ§  Further research or recent breakthroughs addressing the skepticism around LLMs' inherent planning capabilities would be an interesting area to investigate.  
  
## ğŸ“š Book Recommendations  
* ğŸ“– **[ğŸ¤–ğŸ§  Artificial Intelligence: A Modern Approach](../books/artificial-intelligence-a-modern-approach.md)** by Stuart Russell and Peter Norvig: A classic foundational text in AI, defining the field and intelligent agents, offering a comprehensive overview.  
* ğŸ“˜ **[ğŸ¤–ğŸ—ï¸ AI Engineering: Building Applications with Foundation Models](../books/ai-engineering-building-applications-with-foundation-models.md)** by Chip Huyen: The source from which this post is adapted, likely offering a more in-depth exploration of the topics discussed, especially the practical aspects of building AI systems.  
* **[ğŸ’¾â¬†ï¸ğŸ›¡ï¸ Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems](../books/designing-data-intensive-applications.md)** by Martin Kleppmann: While not directly about AI agents, this book provides essential knowledge on building robust, scalable, and reliable data systems, which are often the backbone for agents requiring extensive data access and processing.  
* **[ğŸ¤”ğŸ‡ğŸ¢ Thinking, Fast and Slow](../books/thinking-fast-and-slow.md)** by Daniel Kahneman: Explores the two systems that drive the way we think, offering insights into cognitive processes that could be analogously applied to understanding how AI models "reason" and "plan," and their potential biases or limitations.  
* **[ğŸ§¬ğŸ‘¥ğŸ’¾ Life 3.0: Being Human in the Age of Artificial Intelligence](../books/life-3-0.md)** by Max Tegmark: Provides a broader philosophical perspective on the future of AI and its potential impact on humanity, relevant for considering the long-term implications of advanced autonomous agents.